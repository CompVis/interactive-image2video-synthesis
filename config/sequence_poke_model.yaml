# Here goes all training information and the required parameters; this file can be filled propperly and renamed
general:
  # add base directory: here'll go all the logs and training info about the run
  base_dir: "/export/scratch/ablattma/visual_poking/"
  # whether to start the training/testing run in debug mode
  debug: False
  # if project name is already existing and not restart_from_checkpoint or infer, then an error is thrown
  #project_name: plants-deep-maxf8-bs8-skip-64-mins16-com_tmp_disc #plants-deep-maxf13-bs6-skip-128-mins16-common_tmp_disc_gp.1   # plants-deep-maxf8-bs3-skip-64-mins8-com_tmp_disc
  experiment: sequence_poke_model
  seed: 42

data:
  dataset: IperDataset
  datapath: /export/scratch/compvis/datasets/iPER/processed_256_resized
  spatial_size: !!python/tuple [128,128]
  poke_size: 5
  n_pokes: 1
  # whether to split after videos or randomly (in a reproducible way)
  split: official
  num_workers: 20
  excluded_objects: [] # for iper leave empty, for plants, use [8]
  # list containing the lags, curren6l, its indices are allowed to be within the intervall [0,5], otherwise, an error is throw
  # can be in [image, video]
  yield_videos: True
  # augmentation parameters for color transformations
  p_col: 0.8
  p_geom: 0.8
  augment_b: 0.4
  augment_c: 0.5
  augment_h: 0.15
  augment_s: 0.4
  # augmentation parameters for geometric transformations
  aug_deg: 15 # for iper use 0, for plants use 30Â°
  # translation is (vertical, horizontal)
  aug_trans: !!python/tuple [0.1,0.1] # for iper use [0.1,0.6], for plants use [0.1,0.1]
  # whether to get flow weights
  foreground_value: 10.
  background_weight: 1.
  # filter
  filter: all
  fancy_aug: False
  normalize_flows: True
  # whether to load flow/images in ram
  flow_in_ram: False
  imgs_in_ram: False
  # sequence parameters
  max_frames: 9
  var_sequence_length: True
  object_weighting: True
  include_zeropoke: True
  augment_wo_dis: True
  weight_zeropoke: True
  equal_poke_val: True
  # option to separately weigh the sequence with longest length, as otherwise, the model is biased towards favoring small sequence lengths
  longest_seq_weight: 20



training:
  n_epochs: 1000
  lr: 0.0001
  batch_size: 8
  lr_reduce: 0.3
  # gets multiplicated with n_epochs
  tau: [0.2,0.45,0.7]   #1. means no schedule
  #weight_decay: 0.
  # weight for the dynamics regularizer
  pixel_dynamics_vgg: False
  latent_dynamics_weight: 5.
  pixel_dynamics_weight: 0.
  pixel_dyn_spatial: True
  vgg_dyn_weight: 5.
  style_loss_weight: 0.5
  norm_loss_weight: 0.
  lr_dec_end_it: 35000
  lr_dec_end_val: 0.0001
  fancy_vgg_weights: False
  decoder_update_tk: True
  kl_weight: .001
  stop_seq_stat: 100
  two_stage: True

architecture:
  nf_first: 32
  nf_deep: 512
  min_spatial_size: 16
  zeroflow_baseline: False
  # if adain is used, the decoder is fed the appearance representation via ADAIN
  disentanglement: False
  poke_and_img: False
  # whether to downsample in final resnet blocks of the appearance encoder (exected better appearance code, as alternative is an average pooling over 16x16 spatial res
  # only enable if adain is used
  resnet_down: True
  # whether to apply skip connection
  use_skip_model: True
  poke_every_t: True
  spectnorm_decoder: False
  dynamics_var: False
  norm_layer: in



# if patch discriminator is used
gan:
  use: True
  n_layers: 3
  gp_weight: 0.0001
  fmap_weight: 0.
  pixel_dynamics: False
  gen_weight: 1
  bce_loss: False
  deep_disc: False
  deep_layers: 1
  start_iteration: 4000  #8000
  n_examples: 16

gan_temp:
  use: True
  gp_weight: .1
  fmap_weight: 10.
  gen_weight: 1
  bce_loss: False
  start_iteration: 4000 #8000
  patch_temp_disc: True
  num_classes: 1
  conditional: False
  base_norm_spade: instance


testing:
  ckpt_intervall: 1000
  log_intervall: 500   # use 300
  test_img_intervall: 500 # use 500
  n_epoch_metrics: 1
  test_batch_size: 4
  n_logged_img: 4
  n_test_img: 16
  test_it: 4
  eval_app_transfer: False
  # computes metrics on patches, if patches are available for the selected dataset
  metrics_on_patches: False

  # evaluation
  n_examples_noise: 10


ui:
  ckpt_strategy: "latest"
  ckpt_dir: None # /export/scratch2/ablattma/visual_poking/sequence_poke_model/ckpt/iper-maxf10-bs12-skip-64-ldl5-pdl0-vgg5-patchganorig_gp.0001-gantmpold.1gpfmap10-offsplit-rightzeropoke-nopokeimg/good_ckpt
  ckpt_name: None #reg_ckpt_checkpoint_147000.pt
  display_size: 128
  debug: False
  fixed_length: False
  seq_length_to_generate: 20
  fps: 8
  save_gif: True
  fixed_seed: False
  project_name: iper-deep-maxf9-bs3-skip-128-ldl5-pdl0-vgg5-patchganorig_gp.0001-gantmpold.1gpfmap10-longseq20 #taichi-deep-maxf13-bs6-skip-128-mins16-patch_tmp_disc_gp
  interactive: False
  n_gt_pokes: 5
  #taichi-deep-maxf13-bs6-skip-128-mins16-patch_tmp_disc_gp
  # largeveg-deep-maxf8-bs3-skip-128-ldl5-pdl0-vgg5-patchganorig_gp.0001-gantmpold.1gpfmap10-nopokeimg-two_stage
  # plants-maxf8-bs8-nodis-skip-64-ldl5-pdl0-vgg5-patchganorig_gp.0001-gantmpold.1gpfmap10-equal_poke-deep-weighted
  # iper-maxf10-bs12-skip-64-ldl5-pdl0-vgg5-patchganorig_gp.0001-gantmpold.1gpfmap10-offsplit-rightzeropoke-nopokeimg
  # iper-maxf10-bs12-skip-64-ldl5-pdl0-vgg5-patchganorig_gp.0001-gantmpold.1gpfmap10-nopokeimg-onlypoket1
  # taichi-maxf10-bs12-skip-64-ldl5-pdl0-vgg5-patchganorig_gp.0001-gantmpold.1gpfmap10-offsplit-rightzeropoke-nopokeimg
  # h36m-maxf5-bs5-skip-64-ldl5-pdl0-vgg5-patchganorig_gp.0001-gantmpold.1gpfmap10_uncond-offsplit-nonpokeimg
  # plants-deep-maxf10-bs12-skip-64-ldl5-pdl0-vgg5-patchganorig_gp.0001-gantmpold.1gpfmap10-nopokeimg

  # different train test split
  # iper-maxf10-bs12-nodis-skip-64-ldl5-pdl0-vgg5-patchganorig_gp.0001-gantmpold.1gpfmap10_uncond-equal_poke_wfilt-offsplit
  # h36m-maxf5-bs5-nodis-skip-128-ldl5-pdl0-vgg5-patchganorig_gp.0001-gantmpold.1gpfmap10-zeropoke_magn_weight-aug